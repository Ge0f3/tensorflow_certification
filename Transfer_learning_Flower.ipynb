{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_learning_Flower.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ge0f3/tensorflow_certification/blob/main/Transfer_learning_Flower.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV5UNEBv2Nnb",
        "outputId": "49987157-6874-4006-982d-fd0359b6284d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        }
      },
      "source": [
        "!pip install tf-nightly-gpu\n",
        "!pip install \"tensorflow_hub==0.4.0\"\n",
        "!pip install -U tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-gpu in /usr/local/lib/python3.6/dist-packages (1.14.1.dev20190624)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.33.4)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.14.0.dev2019062401)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.16.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.11.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.1.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.14.0a20190614)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly-gpu) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-gpu) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-gpu) (0.15.4)\n",
            "Requirement already satisfied: tensorflow_hub==0.4.0 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (1.16.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub==0.4.0) (41.0.1)\n",
            "Requirement already up-to-date: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.11.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.13.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.2.9)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow_datasets) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tensorflow_datasets) (2019.3.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48OXFPq42r7g"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9zwsvIM3ZCD"
      },
      "source": [
        "import logging\n",
        "import os \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2zmllZKA8Gi",
        "outputId": "c96cc3b1-43e5-4f7d-b3ed-0ec1e53c2392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Loading the images \n",
        "#Loading the image dataste\n",
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, \n",
        "                                   fname=\"flower_photos.tgz\", \n",
        "                                   extract=True)\n",
        "print(zip_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/flower_data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVNYsg3ZA9pb"
      },
      "source": [
        "#Training and Testing directory \n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'flower_photos')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NodIXoHxBDfB"
      },
      "source": [
        "BATCH_SIZE = 100  # Number of training examples to process before updating our models variables\n",
        "IMG_SHAPE  = 224  # Our training data consists of images with width of 150 pixels and height of 150 pixels\n",
        "train_image_generator      = ImageDataGenerator(rescale=1./255,\n",
        "                                               rotation_range=40,\n",
        "                                                            width_shift_range=0.2,\n",
        "                                                            height_shift_range=0.2,\n",
        "                                                            shear_range=0.2,\n",
        "                                                            zoom_range=0.2,\n",
        "                                                            horizontal_flip=True,\n",
        "                                                            fill_mode='nearest')  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEUj2WtEBNLI",
        "outputId": "643c6296-ddda-422e-9354-9fec878d72a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE, \n",
        "                                                           directory=base_dir, \n",
        "                                                           shuffle=True, \n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150) \n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3670 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1pMj6iJ3a8y"
      },
      "source": [
        "#loading the state of art neural network \n",
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
        "\n",
        "IMAGE_RES = 224\n",
        "\n",
        "feature_extractor =  hub.KerasLayer(URL,input_shape = (IMAGE_RES,IMAGE_RES,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqN_hu3r9jmK",
        "outputId": "38290ca7-25cc-4993-e453-ce62ad762cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feature_extractor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_hub.keras_layer.KerasLayer at 0x7f20a5f5cdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw_jsAAa-uHr"
      },
      "source": [
        "#Freezing so that the training modeifies only the final layer\n",
        "feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No2nI63k_iCY",
        "outputId": "0e9167a0-87cf-4233-ea60-29643fc7e31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    feature_extractor,\n",
        "    layers.Dense(5,activation='softmax')\n",
        "    \n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_3 (KerasLayer)   (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 6405      \n",
            "=================================================================\n",
            "Total params: 2,264,389\n",
            "Trainable params: 6,405\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHdr_9GLBWUP"
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpCHl7EjBTAP",
        "outputId": "dfcdcbe3-87ea-4a15-906e-1b610b1cddc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "EPOCHS=15\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=10,\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 18s 2s/step - loss: 1.7815 - acc: 0.2780\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 18s 2s/step - loss: 1.2445 - acc: 0.5490\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 19s 2s/step - loss: 0.9824 - acc: 0.6784\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.8388 - acc: 0.7510\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.7262 - acc: 0.7730\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.6977 - acc: 0.7784\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.6438 - acc: 0.8150\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.5854 - acc: 0.8440\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.6162 - acc: 0.7990\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.6020 - acc: 0.8190\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.5770 - acc: 0.8240\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 18s 2s/step - loss: 0.5367 - acc: 0.8474\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.5469 - acc: 0.8330\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 17s 2s/step - loss: 0.5399 - acc: 0.8490\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.5114 - acc: 0.8546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qHTIFCDFGWl",
        "outputId": "94841137-a0df-41b2-98e5-56f67c1650eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.278,\n",
              "  0.549,\n",
              "  0.6783505,\n",
              "  0.751,\n",
              "  0.773,\n",
              "  0.77835053,\n",
              "  0.815,\n",
              "  0.844,\n",
              "  0.799,\n",
              "  0.819,\n",
              "  0.824,\n",
              "  0.84742266,\n",
              "  0.833,\n",
              "  0.849,\n",
              "  0.8546392],\n",
              " 'loss': [1.7814883828163146,\n",
              "  1.2445054411888123,\n",
              "  0.9838162470109684,\n",
              "  0.838788914680481,\n",
              "  0.7262226402759552,\n",
              "  0.696004018955624,\n",
              "  0.6437859237194061,\n",
              "  0.5854247272014618,\n",
              "  0.6161675572395324,\n",
              "  0.6020499289035797,\n",
              "  0.5770085334777832,\n",
              "  0.535695210560081,\n",
              "  0.5469098448753357,\n",
              "  0.5399455100297927,\n",
              "  0.5129684925693827]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8sDOLitFo0F",
        "outputId": "114ec231-6934-494c-e2ab-6021f97e7cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig('./foo.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-39402d31df08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        }
      ]
    }
  ]
}